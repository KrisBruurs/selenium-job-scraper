{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817dc43e-812a-4d25-ba4d-8374979c8739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebDriver initialized.\n",
      "\n",
      "--- Phase 1: Collecting Job Links ---\n",
      "Scraping page 1: https://weworkremotely.com/top-trending-remote-jobs?page=1\n",
      "Cookies accepted (or attempted).\n",
      "Found 51 potential job listings on page 1\n",
      "Scraping page 2: https://weworkremotely.com/top-trending-remote-jobs?page=2\n",
      "Found 51 potential job listings on page 2\n",
      "Scraping page 3: https://weworkremotely.com/top-trending-remote-jobs?page=3\n",
      "Found 51 potential job listings on page 3\n",
      "\n",
      "Total unique job links collected: 150\n",
      "Total unique job links after deduplication: 150\n",
      "\n",
      "--- Phase 2: Scraping Detailed Job Data ---\n",
      "Processing job 1/150: https://weworkremotely.com/remote-jobs/bbe-marketing-inc-account-manager-8\n",
      "Processing job 2/150: https://weworkremotely.com/remote-jobs/speechify-inc-tech-lead-web-core-product-chrome-extension\n",
      "Processing job 3/150: https://weworkremotely.com/remote-jobs/files-com-ui-ux-designer-2\n",
      "Processing job 4/150: https://weworkremotely.com/remote-jobs/evaboot-customer-support-build-the-ai-that-will-steal-your-job\n",
      "Processing job 5/150: https://weworkremotely.com/remote-jobs/speechify-inc-software-engineer-platform\n",
      "Processing job 6/150: https://weworkremotely.com/remote-jobs/bbe-marketing-inc-graphic-designer-social-media-manager\n",
      "Processing job 7/150: https://weworkremotely.com/remote-jobs/clipboard-health-client-support-specialist-healthcare-facilities-b2b-1\n",
      "Processing job 8/150: https://weworkremotely.com/remote-jobs/sweat-pants-agency-media-buyer-1\n",
      "Processing job 9/150: https://weworkremotely.com/remote-jobs/forager-growth-marketing-manager\n",
      "Processing job 10/150: https://weworkremotely.com/remote-jobs/packtrip-land-staff-accountant\n",
      "Processing job 11/150: https://weworkremotely.com/remote-jobs/a-insurance-designers-senior-digital-marketing-specialist\n",
      "Processing job 12/150: https://weworkremotely.com/remote-jobs/the-lawgical-firm-p-a-virtual-assistant-bilingual-with-vietnamese-and-english-required\n",
      "Processing job 13/150: https://weworkremotely.com/remote-jobs/mailerlite-web-designer-2\n",
      "Processing job 14/150: https://weworkremotely.com/remote-jobs/volcano-builders-remote-administrative-operations-assistant\n",
      "Processing job 15/150: https://weworkremotely.com/remote-jobs/smib-business-development-executive\n",
      "Processing job 16/150: https://weworkremotely.com/remote-jobs/ima-financial-group-account-executive-underwriter\n",
      "Processing job 17/150: https://weworkremotely.com/remote-jobs/brook-hiddink-highticket-io-a-i-video-editor-direct-response-veo3\n",
      "Processing job 18/150: https://weworkremotely.com/remote-jobs/the-humble-hackers-generative-ai-trends-analyst-part-time-remote\n",
      "Processing job 19/150: https://weworkremotely.com/remote-jobs/telus-digital-us-internet-rater-english-language\n",
      "Processing job 20/150: https://weworkremotely.com/remote-jobs/canara-bank-securities-limited-freelance-facebook-google-ads-expert-india-remote-10k-15k-per\n",
      "Processing job 21/150: https://weworkremotely.com/remote-jobs/accesa-senior-ux-ui-designer-with-german\n",
      "Processing job 22/150: https://weworkremotely.com/remote-jobs/pr-volt-outbound-sales-specialist\n",
      "Processing job 23/150: https://weworkremotely.com/remote-jobs/melapress-wordpress-plugins-themes-developer\n",
      "Processing job 24/150: https://weworkremotely.com/remote-jobs/spiralyze-ui-ux-designer\n",
      "Processing job 25/150: https://weworkremotely.com/remote-jobs/proudfoot-proudfoot-presenting-analyst-united-kingdom-europe-the-americas\n",
      "Processing job 26/150: https://weworkremotely.com/remote-jobs/paymentology-implementation-project-manager-2\n",
      "Processing job 27/150: https://weworkremotely.com/remote-jobs/sana-vita-operations-llc-project-coordinator\n",
      "Processing job 28/150: https://weworkremotely.com/remote-jobs/vidalytics-europe-only-growth-product-manager-at-video-martech-saas\n",
      "Processing job 29/150: https://weworkremotely.com/remote-jobs/scholarshipowl-affiliate-manager\n",
      "Processing job 30/150: https://weworkremotely.com/remote-jobs/mint-lily-ecommerce-operations-manager\n",
      "Processing job 31/150: https://weworkremotely.com/remote-jobs/howie-ai-remote-scheduling-calendar-assistant-1\n",
      "Processing job 32/150: https://weworkremotely.com/remote-jobs/lumenalta-javascript-fullstack-engineer-senior\n",
      "Processing job 33/150: https://weworkremotely.com/remote-jobs/apicworld-finance-accounting-specialist-lithuania-estonia\n",
      "Processing job 34/150: https://weworkremotely.com/remote-jobs/creative-force-product-specialist-jedi-german-speaking\n",
      "Processing job 35/150: https://weworkremotely.com/remote-jobs/melapress-content-led-marketer-b2b-startup-mentality\n",
      "Processing job 36/150: https://weworkremotely.com/remote-jobs/hey-contact-heroes-gmbh-eu-freelancer-m-w-d-im-inbound-kundenservice-home-office-1\n",
      "Processing job 37/150: https://weworkremotely.com/remote-jobs/hb-travels-remote-travel-booking-specialists\n",
      "Processing job 38/150: https://weworkremotely.com/remote-jobs/contra-content-creators-for-viral-video-project\n",
      "Processing job 39/150: https://weworkremotely.com/remote-jobs/appmagic-senior-sales-manager\n",
      "Processing job 40/150: https://weworkremotely.com/remote-jobs/proxify-ab-senior-django-developer-1\n",
      "Processing job 41/150: https://weworkremotely.com/remote-jobs/waifu-masters-head-of-social-social-media-manager\n",
      "Processing job 42/150: https://weworkremotely.com/remote-jobs/subscript-software-engineer-frontend-backend-or-full-stack-2\n",
      "Processing job 43/150: https://weworkremotely.com/remote-jobs/crisp-ui-ux-designer\n",
      "Processing job 44/150: https://weworkremotely.com/remote-jobs/intellisync-srl-senior-software-engineer\n",
      "Processing job 45/150: https://weworkremotely.com/remote-jobs/flag-theory-ifrs-accountant-with-multiple-jurisdiction-experience\n",
      "Processing job 46/150: https://weworkremotely.com/remote-jobs/credit-clerk-inside-sales-representative-u-s-market\n",
      "Processing job 47/150: https://weworkremotely.com/remote-jobs/mailerlite-product-designer-3\n",
      "Processing job 48/150: https://weworkremotely.com/remote-jobs/escorial-future-digital-asset-operations\n",
      "Processing job 49/150: https://weworkremotely.com/remote-jobs/dataannotation-tech-ft-pt-remote-ai-prompt-engineering-evaluation-will-train\n",
      "Processing job 50/150: https://weworkremotely.com/remote-jobs/ae-virtual-class-s-a-languages-teachers\n",
      "Processing job 51/150: https://weworkremotely.com/remote-jobs/canva-staff-backend-engineer-java-admin-experience-open-to-remote-across-anz\n",
      "Processing job 52/150: https://weworkremotely.com/remote-jobs/zapiet-experienced-laravel-developer-apac-region\n",
      "Processing job 53/150: https://weworkremotely.com/remote-jobs/hummingbird-revops-manager\n",
      "Processing job 54/150: https://weworkremotely.com/remote-jobs/amazowl-amazon-ecommerce-account-manager-seller-vendor\n",
      "Processing job 55/150: https://weworkremotely.com/remote-jobs/baymard-institute-financial-customer-support-accounts-receivables-employee\n",
      "Processing job 56/150: https://weworkremotely.com/remote-jobs/tripleten-creative-producer-remote-ft-contract\n",
      "Error scraping details for link https://weworkremotely.com/remote-jobs/tripleten-creative-producer-remote-ft-contract: HTTPConnectionPool(host='localhost', port=51555): Read timed out. (read timeout=120)\n",
      "Processing job 57/150: https://weworkremotely.com/remote-jobs/sa-global-dynamics-365-customer-engagement-ce-technical-architect\n",
      "\n",
      "WebDriver closed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 154\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo job data scraped. CSV file not created.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     scrape_weworkremotely()\n",
      "Cell \u001b[1;32mIn[4], line 78\u001b[0m, in \u001b[0;36mscrape_weworkremotely\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_job_links)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlink\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(link)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Wait for main elements to be present before scraping\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(EC\u001b[38;5;241m.\u001b[39mpresence_of_element_located((By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlis-container__header__hero__company-info__title\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\undetected_chromedriver\\__init__.py:665\u001b[0m, in \u001b[0;36mChrome.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# if self._get_cdc_props():\u001b[39;00m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;66;03m#     self._hook_remove_cdc_props()\u001b[39;00m\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget(url)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:472\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    455\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Navigate the browser to the specified URL in the current window or\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m    tab.\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03m    >>> driver.get(\"https://example.com\")\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:445\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    443\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 445\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:404\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    402\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    403\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(command_info[\u001b[38;5;241m0\u001b[39m], url, body\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:428\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    425\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 428\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[0;32m    429\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    136\u001b[0m         method,\n\u001b[0;32m    137\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m    144\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m    145\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1430\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m-> 1430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response\u001b[38;5;241m.\u001b[39mwill_close \u001b[38;5;241m!=\u001b[39m _UNKNOWN\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:320\u001b[0m, in \u001b[0;36mHTTPConnection.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    Return True if a tunneling proxy is configured, else return False\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import re\n",
    "import json # If you decide to output JSON first\n",
    "\n",
    "def accept_cookies(driver_instance):\n",
    "    \"\"\"Attempts to accept cookie consent popups.\"\"\"\n",
    "    try:\n",
    "        # Prioritize more common/broad selectors\n",
    "        # These are examples, you might need to combine or try more specific ones\n",
    "        WebDriverWait(driver_instance, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.fc-button, button.adroll_button_text, #adroll_consent_allow_all, .fc-cta-consent'))).click()\n",
    "        # Give it a moment for popups to disappear\n",
    "        time.sleep(1)\n",
    "        print(\"Cookies accepted (or attempted).\")\n",
    "    except Exception:\n",
    "        print(\"Cookie buttons not found or already accepted/handled.\")\n",
    "\n",
    "def scrape_weworkremotely():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\") # Only if you need the full window, might be slower for headless\n",
    "\n",
    "    driver = uc.Chrome(options=options)\n",
    "    print(\"WebDriver initialized.\")\n",
    "\n",
    "    base_url = \"https://weworkremotely.com/top-trending-remote-jobs?page=\"\n",
    "    urls = [f\"{base_url}{i}\" for i in range(1, 4)] # scrape pages 1 to 3\n",
    "\n",
    "    all_job_links = []\n",
    "    job_data = [] # Data container for detailed job info\n",
    "\n",
    "    try: # Main try block for overall process\n",
    "        # === Phase 1: Collect Job Links ===\n",
    "        print(\"\\n--- Phase 1: Collecting Job Links ---\")\n",
    "        for index, url in enumerate(urls):\n",
    "            driver.get(url)\n",
    "            print(f\"Scraping page {index + 1}: {url}\")\n",
    "\n",
    "            # Attempt to accept cookies on the first page load or any page load\n",
    "            if index == 0: # Or just call it on the first successful page load\n",
    "                accept_cookies(driver)\n",
    "\n",
    "            # Scroll to bottom to load all info\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(random.uniform(3, 6))\n",
    "\n",
    "            # Scrape job links\n",
    "            job_links_elements = driver.find_elements(By.CSS_SELECTOR, \"section.jobs li > a\")\n",
    "            print(f\"Found {len(job_links_elements)} potential job listings on page {index + 1}\")\n",
    "\n",
    "            page_links = [\n",
    "                link.get_attribute(\"href\")\n",
    "                for link in job_links_elements\n",
    "                if link.get_attribute(\"href\") and link.get_attribute(\"href\") != \"https://weworkremotely.com/\"\n",
    "            ]\n",
    "            all_job_links.extend(page_links)\n",
    "\n",
    "            time.sleep(random.uniform(2, 5)) # Random delay between pages\n",
    "\n",
    "        print(f\"\\nTotal unique job links collected: {len(all_job_links)}\")\n",
    "        # You might want to remove duplicates here too\n",
    "        all_job_links = list(set(all_job_links))\n",
    "        print(f\"Total unique job links after deduplication: {len(all_job_links)}\")\n",
    "\n",
    "\n",
    "        # === Phase 2: Scrape Detailed Job Data ===\n",
    "        print(\"\\n--- Phase 2: Scraping Detailed Job Data ---\")\n",
    "        for i, link in enumerate(all_job_links):\n",
    "            print(f\"Processing job {i+1}/{len(all_job_links)}: {link}\")\n",
    "            try:\n",
    "                driver.get(link)\n",
    "\n",
    "                # Wait for main elements to be present before scraping\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'lis-container__header__hero__company-info__title')))\n",
    "\n",
    "                job_title = driver.find_element(By.CLASS_NAME, 'lis-container__header__hero__company-info__title').text\n",
    "                company_block = driver.find_element(By.CLASS_NAME, 'lis-container__job__sidebar__companyDetails__info')\n",
    "                company_title = company_block.find_element(By.CLASS_NAME, 'lis-container__job__sidebar__companyDetails__info__title').text\n",
    "\n",
    "                try:\n",
    "                    jobs_posted_text = WebDriverWait(company_block, 10).until( # Reduced wait time\n",
    "                        EC.visibility_of_element_located((By.CLASS_NAME, 'lis-container__job__sidebar__companyDetails__info__jobs-posted'))\n",
    "                    ).text.strip()\n",
    "                except:\n",
    "                    jobs_posted_text = \"NA\"\n",
    "                    print(f\"  Warning: 'Jobs Posted' not found for {link}\")\n",
    "\n",
    "                job_block = driver.find_element(By.CLASS_NAME, 'lis-container__job__sidebar__job-about')\n",
    "                category_items = job_block.find_elements(By.CLASS_NAME, 'lis-container__job__sidebar__job-about__list__item')\n",
    "\n",
    "                job_details = {}\n",
    "                for item in category_items:\n",
    "                    lines = item.text.strip().split(\"\\n\")\n",
    "                    if len(lines) >= 2:\n",
    "                        label = lines[0].strip()\n",
    "                        value = \"\\n\".join(lines[1:]).strip()\n",
    "                        job_details[label] = value\n",
    "\n",
    "                region_raw = job_details.get(\"Region\", \"NA\")\n",
    "                # Simplified region extraction\n",
    "                region_extracted = \"NA\"\n",
    "                if \" Only\" in region_raw:\n",
    "                    region_extracted = region_raw.split(\" Only\")[0].strip() + \" Only\"\n",
    "                elif region_raw != \"NA\": # If it's not \"NA\" but also not \"X Only\"\n",
    "                    region_extracted = region_raw # Keep the raw value if it's not an \"Only\" pattern\n",
    "\n",
    "                job_entry = {\n",
    "                    \"Ranking\": i + 1, # This ranking will be based on scrape order, not website ranking\n",
    "                    \"Job Title\": job_title,\n",
    "                    \"Company\": company_title,\n",
    "                    \"Jobs Posted\": jobs_posted_text.replace(\"Jobs posted: \", \"\"),\n",
    "                    \"Job Type\": job_details.get(\"Job type\", \"NA\"),\n",
    "                    \"Category\": job_details.get(\"Category\", \"NA\"),\n",
    "                    \"Salary\": job_details.get(\"Salary\", \"NA\"),\n",
    "                    \"Region\": region_extracted,\n",
    "                    \"Link\": link\n",
    "                }\n",
    "\n",
    "                job_data.append(job_entry)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping details for link {link}: {e}\")\n",
    "                # Optional: log failed links to a separate list\n",
    "                # failed_links.append(link)\n",
    "\n",
    "            time.sleep(random.uniform(1, 3)) # Variable delay between detail requests\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Critical error during scraping process: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(\"\\nWebDriver closed.\")\n",
    "\n",
    "    # Write to CSV\n",
    "    if job_data: # Only write if there's data\n",
    "        output_file_name = \"top_trending_jobs.csv\"\n",
    "        with open(output_file_name, \"w\", newline='', encoding='utf-8') as f:\n",
    "            fieldnames = list(job_data[0].keys()) # Get headers from first entry\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(job_data)\n",
    "        print(f\"Scraped {len(job_data)} jobs and saved to '{output_file_name}'\")\n",
    "    else:\n",
    "        print(\"No job data scraped. CSV file not created.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    scrape_weworkremotely()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
